# ğŸ¥ Emotional State Detection Through Video

This project implements an emotional state detection system that analyzes the emotions of a person from a video file. The system uses deep learning models to detect facial expressions from video frames and predict the corresponding emotional state, all while creating a seamless and interactive user experience. ğŸŒŸ

## Project Structure

```bash
app/
â”‚
â”œâ”€â”€ .dockerignore                # Specifies files to be excluded from Docker builds
â”œâ”€â”€ .gitattributes               # Git settings for handling line endings and other attributes
â”œâ”€â”€ Dockerfile                   # Dockerfile for containerizing the application
â”œâ”€â”€ main.py                      # Main application script that runs the emotion detection pipeline
â”œâ”€â”€ requirements.txt             # Required Python packages for the project
â”œâ”€â”€ sample.py                    # Example script for reference
â”‚
â”œâ”€â”€ extracted_data/
â”‚   â””â”€â”€ emotions_data.csv         # Stores the detected emotions from video processing
â”‚
â”œâ”€â”€ initial_code/
â”‚   â””â”€â”€ Emotion_detector.py       # Initial code or reference implementation for emotion detection
â”‚
â”œâ”€â”€ output/
â”‚   â””â”€â”€ output_video.mp4          # Output video with detected emotions overlaid on faces
â”‚
â”œâ”€â”€ pages/
â”‚   â””â”€â”€ Emotion_Prediction.py     # Additional pages for the Streamlit app (if needed)
â”‚
â””â”€â”€ utils/
    â”œâ”€â”€ haarcascade_frontalface_default.xml  # Haar Cascade file for face detection
    â”œâ”€â”€ Model.h5                            # Pre-trained emotion detection model
    â””â”€â”€ temp_video.mp4                      # Temporary storage for uploaded video
```

## 1. Overview

ğŸ“Š The application leverages a pre-trained Convolutional Neural Network (CNN) model to predict emotions based on facial expressions detected in a video. Using **Streamlit** for a user-friendly interface, and **OpenCV** to process video frames and detect faces, the application predicts emotions, stores the data in a CSV file, and overlays labels on the processed video. 

Additionally, the processed video can be previewed with real-time emotion annotations for each face in the video. This adds an engaging touch by showing emotional transitions as the video plays! ğŸ¬ğŸ˜ƒ

## 2. Features

âœ¨ **Key Highlights:**
- ğŸ¥ **Video Upload:** Users can upload an `.mp4` video for emotion detection.
- ğŸ‘¤ **Face Detection:** Uses OpenCV's Haar Cascade to detect faces in each frame.
- ğŸ¤– **Emotion Prediction:** Predicts emotions using a pre-trained model (`Model.h5`) and labels the dominant emotion for each detected face.
- ğŸ“Š **CSV Output:** Extracted emotions are saved in a CSV file for further analysis.
- ğŸ“½ï¸ **Video Output:** Generates an output video with detected emotions overlaid on each detected face.
- ğŸ–¥ï¸ **Streamlit Interface:** Simple, interactive web interface for video upload, processing, and result preview.

## 3. Emotion Classes

The model is trained to detect the following emotions:
- ğŸ˜¡ Angry
- ğŸ˜’ Disgust
- ğŸ˜± Fear
- ğŸ˜Š Happy
- ğŸ˜¢ Sad
- ğŸ˜² Surprise
- ğŸ˜ Neutral

These emotions are visually displayed on the detected faces throughout the video, making it easier to observe how emotions change over time. â³

## 4. How It Works

1. ğŸ“¥ **Model Loading:** The pre-trained CNN model (`Model.h5`) is loaded along with the Haar Cascade classifier for face detection.
2. ğŸ¦ **Video Processing:** The user uploads a video file, and the application processes it frame by frame.
3. ğŸ§  **Face Detection:** Faces are detected in each frame using the Haar Cascade classifier.
4. ğŸ¤” **Emotion Prediction:** For each detected face, the emotion is predicted by the CNN model, and the dominant emotion is labeled.
5. ğŸ¬ **Output Generation:** The processed video with emotion labels is displayed to the user, and the emotion data is saved in `emotions_data.csv`. The video playback also reflects changes in emotional states throughout the video! ğŸ“ŠğŸ¥

## 5. Installation

To run the project locally, follow these steps:

1. Clone the repository:
    ```bash
    git clone https://github.com/itzmechandruganeshan/Emotion_Prediction.git
    ```

2. Navigate to the project directory:
    ```bash
    cd app
    ```

3. Install the required packages:
    ```bash
    pip install -r requirements.txt
    ```

4. Run the Streamlit app:
    ```bash
    streamlit run main.py
    ```

## 6. Dependencies

The project requires the following Python packages:

- `opencv-python` ğŸ–¼ï¸
- `tensorflow` ğŸ¤–
- `keras` ğŸ”¬
- `numpy` ğŸ”¢
- `pandas` ğŸ“Š
- `streamlit` ğŸŒ

These can be installed using the `requirements.txt` file.

## 7. Usage

1. ğŸš€ Launch the application using Streamlit.
2. ğŸ“¤ Upload a video file in `.mp4` format.
3. ğŸ•°ï¸ Wait for the video processing to complete.
4. ğŸ¥ The detected emotions will be overlaid on the faces in the video.
5. ğŸ’¾ Download the generated CSV file with emotion data for further analysis.
